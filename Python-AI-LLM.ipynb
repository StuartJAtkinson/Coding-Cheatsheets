{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install jupyterlab==4.2.1 openai==1.38.0 langchain-ollama==0.1.1 langchain-openai==0.1.19 litellm==1.42.11 icecream==2.1.3 tiktoken==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "#warnings.simplefilter(\"ignore\", category=Warning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myZYsW9oZkEv",
    "outputId": "0abe91b3-d4a6-43ce-a0f3-5d99734e1b55"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Secrets (JSON string):  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable not found. Setting values...\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, Markdown,display\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import psutil\n",
    "import re\n",
    "import requests\n",
    "from getpass import getpass\n",
    "import openai\n",
    "from os import environ\n",
    "\n",
    "IN_NOTEBOOK = any([\"jupyter-lab\" in i for i in psutil.Process().parent().cmdline()])\n",
    "if IN_NOTEBOOK:\n",
    "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
    "  os.environ['CREDS'] = json.dumps(CREDS)\n",
    "  CREDS = json.loads(os.getenv('CREDS'))\n",
    "\n",
    "if environ.get('OPENAI_API_KEY') is None:\n",
    "    print('Environment variable not found. Setting values...')\n",
    "    os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v1']['credential'] \n",
    "    os.environ[\"TOGETHERAI_API_KEY\"] = CREDS['together-ai']['key']['credential']\n",
    "    os.environ['ANTHROPIC_API_KEY'] = CREDS['anthropic']['key']['credential']\n",
    "    os.environ[\"SERPER_API_KEY\"] = CREDS['serper_dev']['key']['credential']\n",
    "    #openai.api_key = CREDS['OpenAI']['v2']['credential'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y0pi_2z0ZsOS"
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4y8G15cWMRuX"
   },
   "source": [
    "# List available models\n",
    "\n",
    "see https://platform.openai.com/docs/models\n",
    "\n",
    "**or via bash:**\n",
    "\n",
    "%%bash\n",
    "\n",
    "curl https://api.openai.com/v1/models -H \"Authorization: Bearer $OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZ-tggc8Kr8c",
    "outputId": "2ee9ceee-34b0-45b0-d246-cfd6ae149d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dall-e-3\n",
      "gpt-4-1106-preview\n",
      "dall-e-2\n",
      "tts-1-hd-1106\n",
      "tts-1-hd\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4-0125-preview\n",
      "babbage-002\n",
      "gpt-4-turbo-preview\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "tts-1\n",
      "gpt-3.5-turbo\n",
      "whisper-1\n",
      "gpt-4o-2024-05-13\n",
      "text-embedding-ada-002\n",
      "gpt-3.5-turbo-16k\n",
      "davinci-002\n",
      "gpt-4-turbo-2024-04-09\n",
      "tts-1-1106\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-turbo\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4o-mini\n",
      "gpt-4o\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-0613\n",
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "# Get list of available models\n",
    "client = openai.OpenAI()\n",
    "model_list = client.models.list()\n",
    "for model in model_list:\n",
    "  print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N2G8OUkzXLL"
   },
   "source": [
    "# Simple LLM calls: via OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a program, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# OpenAI\n",
    "\n",
    "client = openai.OpenAI(\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how are you?\",\n",
    "    }\n",
    "  ],\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ku-bklBeaTpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you with any language-related questions you have. Is there something specific you would like to know or practice?\n"
     ]
    }
   ],
   "source": [
    "# Mixtral - via together.ai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "  api_key=os.environ.get(\"TOGETHERAI_API_KEY\"),\n",
    "  base_url='https://api.together.xyz',\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how are you?\",\n",
    "    }\n",
    "  ],\n",
    "  model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thank you for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How about you, how's your day going?\n"
     ]
    }
   ],
   "source": [
    "# Ollama\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"not-needed\",\n",
    "    base_url = \"http://localhost:11434/v1\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how are you?\",\n",
    "    }\n",
    "  ],\n",
    "  model=\"llama3.1:8b\", # this field is currently unused\n",
    "  temperature=0.7,\n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NslOVAbzJtKP"
   },
   "outputs": [],
   "source": [
    "# LM Studio\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"not-needed\",\n",
    "    base_url=\"http://localhost:1234/v1\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how are you?\",\n",
    "    }\n",
    "  ],\n",
    "  model=\"local-model\", # this field is currently unused\n",
    "  temperature=0.7,\n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LLM calls: via Langchain\n",
    "\n",
    "llm is defined by factory 'get_llm' - can easilly switched between Ollama and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def get_llm(llm_type):\n",
    "    if llm_type == \"ollama\":\n",
    "        return ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "    else:\n",
    "        return ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "def get_embeddings(embedding_type):\n",
    "    if embedding_type == \"ollama\":\n",
    "        return OllamaEmbeddings(model=\"llama3.1:8b\")\n",
    "    else:\n",
    "        return OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! When considering what dogs like to eat, we can break it down into several categories:\n",
      "\n",
      "1. **Commercial Dog Food**: Most dog owners feed their pets commercial dog food, which comes in dry (kibble) and wet (canned) forms. These foods are formulated to meet a dog's nutritional needs.\n",
      "\n",
      "2. **Meat**: Dogs are carnivores by nature, so they typically enjoy eating meat. Common options include:\n",
      "   - Chicken\n",
      "   - Beef\n",
      "   - Turkey\n",
      "   - Fish\n",
      "\n",
      "3. **Fruits and Vegetables**: Many dogs enjoy certain fruits and vegetables, which can be healthy treats. Some popular options include:\n",
      "   - Carrots\n",
      "   - Apples (without seeds)\n",
      "   - Blueberries\n",
      "   - Sweet potatoes\n",
      "   - Green beans\n",
      "\n",
      "4. **Grains**: While dogs don't require grains in their diet, some may enjoy them. Common grains include:\n",
      "   - Rice\n",
      "   - Oats\n",
      "   - Barley\n",
      "\n",
      "5. **Treats**: Dogs often love treats, which can be store-bought or homemade. Popular treats include:\n",
      "   - Biscuits\n",
      "   - Chews (like rawhide or dental chews)\n",
      "   - Peanut butter (make sure it's xylitol-free)\n",
      "\n",
      "6. **Human Food**: Some dogs enjoy small amounts of certain human foods, but it's important to be cautious. Foods that are safe in moderation include:\n",
      "   - Plain cooked eggs\n",
      "   - Plain yogurt\n",
      "   - Cooked lean meats\n",
      "\n",
      "7. **Avoiding Toxic Foods**: It's crucial to know which foods are harmful to dogs. Some foods to avoid include:\n",
      "   - Chocolate\n",
      "   - Grapes and raisins\n",
      "   - Onions and garlic\n",
      "   - Avocado\n",
      "   - Xylitol (a sweetener found in many products)\n",
      "\n",
      "In summary, dogs generally enjoy a variety of foods, especially those that are meaty and flavorful. However, it's essential to ensure that their diet is balanced and safe for their health. Always consult with a veterinarian before making significant changes to a dog's diet.\n",
      "content=\"Sure! When considering what dogs like to eat, we can break it down into several categories:\\n\\n1. **Commercial Dog Food**: Most dog owners feed their pets commercial dog food, which comes in dry (kibble) and wet (canned) forms. These foods are formulated to meet a dog's nutritional needs.\\n\\n2. **Meat**: Dogs are carnivores by nature, so they typically enjoy eating meat. Common options include:\\n   - Chicken\\n   - Beef\\n   - Turkey\\n   - Fish\\n\\n3. **Fruits and Vegetables**: Many dogs enjoy certain fruits and vegetables, which can be healthy treats. Some popular options include:\\n   - Carrots\\n   - Apples (without seeds)\\n   - Blueberries\\n   - Sweet potatoes\\n   - Green beans\\n\\n4. **Grains**: While dogs don't require grains in their diet, some may enjoy them. Common grains include:\\n   - Rice\\n   - Oats\\n   - Barley\\n\\n5. **Treats**: Dogs often love treats, which can be store-bought or homemade. Popular treats include:\\n   - Biscuits\\n   - Chews (like rawhide or dental chews)\\n   - Peanut butter (make sure it's xylitol-free)\\n\\n6. **Human Food**: Some dogs enjoy small amounts of certain human foods, but it's important to be cautious. Foods that are safe in moderation include:\\n   - Plain cooked eggs\\n   - Plain yogurt\\n   - Cooked lean meats\\n\\n7. **Avoiding Toxic Foods**: It's crucial to know which foods are harmful to dogs. Some foods to avoid include:\\n   - Chocolate\\n   - Grapes and raisins\\n   - Onions and garlic\\n   - Avocado\\n   - Xylitol (a sweetener found in many products)\\n\\nIn summary, dogs generally enjoy a variety of foods, especially those that are meaty and flavorful. However, it's essential to ensure that their diet is balanced and safe for their health. Always consult with a veterinarian before making significant changes to a dog's diet.\" response_metadata={'token_usage': {'completion_tokens': 421, 'prompt_tokens': 24, 'total_tokens': 445}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9b0abffe81', 'finish_reason': 'stop', 'logprobs': None} id='run-57b97990-e3bb-4678-b379-eec6e8dbff42-0' usage_metadata={'input_tokens': 24, 'output_tokens': 421, 'total_tokens': 445}\n"
     ]
    }
   ],
   "source": [
    "llm = get_llm('openai')\n",
    "result = llm.invoke(\n",
    "    \"Question: What do dogs like to eat?\"\n",
    "    \"Answer: Let's think step by step.\"\n",
    ")\n",
    "print(result.content)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down what dogs like to eat, step by step.\n",
      "\n",
      "**Step 1: Protein is a Must**\n",
      "Dogs are carnivores, which means they primarily thrive on protein-rich foods. Their natural diet consists of meat, bones, and organs from animals. So, we can conclude that dogs love to eat protein-rich foods.\n",
      "\n",
      "**Step 2: Meat and Poultry**\n",
      "Within the category of protein-rich foods, dogs tend to enjoy meat and poultry products like chicken, beef, lamb, and pork. These are common ingredients in dog food and treats.\n",
      "\n",
      "**Step 3: Variety is Key**\n",
      "While dogs have a strong preference for meat-based foods, they also appreciate variety in their diet. This can include fruits, vegetables, and grains, but these should not be the primary components of their meals.\n",
      "\n",
      "**Step 4: Avoid Human Foods (Mostly)**\n",
      "While it's tempting to share our snacks with our furry friends, many human foods are toxic or unhealthy for dogs. For example, chocolate, onions, garlic, grapes, and raisins can be poisonous to dogs. It's best to stick with dog-specific treats and avoid giving them table scraps.\n",
      "\n",
      "**Step 5: Consider Life Stages**\n",
      "Dogs have different nutritional needs at various stages of their lives. Puppies require more protein and calories than adult dogs, while senior dogs may benefit from joint supplements and easier-to-digest foods.\n",
      "\n",
      "In summary, dogs like to eat a balanced diet rich in protein, with meat and poultry as primary sources. They also appreciate variety, but it's essential to avoid human foods that can harm them.\n",
      "content=\"Let's break down what dogs like to eat, step by step.\\n\\n**Step 1: Protein is a Must**\\nDogs are carnivores, which means they primarily thrive on protein-rich foods. Their natural diet consists of meat, bones, and organs from animals. So, we can conclude that dogs love to eat protein-rich foods.\\n\\n**Step 2: Meat and Poultry**\\nWithin the category of protein-rich foods, dogs tend to enjoy meat and poultry products like chicken, beef, lamb, and pork. These are common ingredients in dog food and treats.\\n\\n**Step 3: Variety is Key**\\nWhile dogs have a strong preference for meat-based foods, they also appreciate variety in their diet. This can include fruits, vegetables, and grains, but these should not be the primary components of their meals.\\n\\n**Step 4: Avoid Human Foods (Mostly)**\\nWhile it's tempting to share our snacks with our furry friends, many human foods are toxic or unhealthy for dogs. For example, chocolate, onions, garlic, grapes, and raisins can be poisonous to dogs. It's best to stick with dog-specific treats and avoid giving them table scraps.\\n\\n**Step 5: Consider Life Stages**\\nDogs have different nutritional needs at various stages of their lives. Puppies require more protein and calories than adult dogs, while senior dogs may benefit from joint supplements and easier-to-digest foods.\\n\\nIn summary, dogs like to eat a balanced diet rich in protein, with meat and poultry as primary sources. They also appreciate variety, but it's essential to avoid human foods that can harm them.\" response_metadata={'model': 'llama3.1', 'created_at': '2024-08-03T13:30:44.91976Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7091333000, 'load_duration': 59103416, 'prompt_eval_count': 28, 'prompt_eval_duration': 303316000, 'eval_count': 326, 'eval_duration': 6727327000} id='run-90324595-797c-4373-8d98-4ae80a8a434e-0' usage_metadata={'input_tokens': 28, 'output_tokens': 326, 'total_tokens': 354}\n"
     ]
    }
   ],
   "source": [
    "llm = get_llm('ollama')\n",
    "result = llm.invoke(\n",
    "    \"Question: What do dogs like to eat?\"\n",
    "    \"Answer: Let's think step by step.\"\n",
    ")\n",
    "print(result.content)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ySXc7-JtKQ"
   },
   "source": [
    "# Simple LLM calls: via lite-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PoaFpFXKc8zE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings in the same way humans do, but I'm here and ready to help you. How can I assist you today?\n",
      "ModelResponse(id='chatcmpl-9s957SpRTw3jnPfHCJX9XAsBhHm9U', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello! I'm just a computer program, so I don't have feelings in the same way humans do, but I'm here and ready to help you. How can I assist you today?\", role='assistant', tool_calls=None, function_call=None))], created=1722691649, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=39, prompt_tokens=13, total_tokens=52), service_tier=None)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI\n",
    "response = completion(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  #model=\"together_ai/togethercomputer/Llama-2-7B-32K-Instruct\",\n",
    "  #model=\"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How about you? How's your day going?\n",
      "ModelResponse(id='chatcmpl-b7a2835a-ed2b-49b5-b1f0-54fbdc67e75c', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"I'm doing well, thanks for asking. I'm a large language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How about you? How's your day going?\", role='assistant', tool_calls=None, function_call=None))], created=1722691731, model='ollama/llama3.1:8b', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=19, completion_tokens=57, total_tokens=76))\n"
     ]
    }
   ],
   "source": [
    "# Ollama\n",
    "response = completion(\n",
    "  # api_base=\"http://localhost:11434\",   # seems to work even without this parameter!\n",
    "  model=\"ollama/llama3.1:8b\", \n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rWKs6LFJtKQ"
   },
   "outputs": [],
   "source": [
    "# LM Studio\n",
    "# see https://litellm.vercel.app/docs/providers/openai_compatible\n",
    "response = completion(\n",
    "  api_base=\"http://localhost:1234/v1\",   # seems to work even without this parameter!\n",
    "  model=\"openai/just-a-dummy-model\", # prefix 'openai/' is required! model name is currently unused in LM Studio\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cS0oRxXJtKR"
   },
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## via Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'validate_user', 'args': {'addresses': '[{\"street\":\"Fake St\",\"city\":\"Boston\",\"state\":\"MA\"},{\"street\":\"Pretend Boulevard\",\"city\":\"Houston\",\"state\":\"TX\"}]', 'user_id': 123}, 'id': 'a49c8db3-7be0-4fdb-b58e-890adab99bb0', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def validate_user(user_id: int, addresses: List) -> bool:\n",
    "    \"\"\"Validate user using historical addresses. \n",
    "\n",
    "        Args:\n",
    "        user_id: (int) the user ID.\n",
    "        addresses: Previous addresses.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "llm = get_llm('ollama') # see functions above\n",
    "llm_with_tools = llm.bind_tools([validate_user])\n",
    "\n",
    "result = llm_with_tools. invoke(\n",
    "    \"Could you validate user 123? They previously lived at \"\n",
    "    \"123 Fake St in Boston MA and 234 Pretend Boulevard in \"\n",
    "    \"Houston TX.\"\n",
    ")\n",
    "print(result.tool_calls)\n",
    "#print(result.content)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## via litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG6qj6W282Dz"
   },
   "outputs": [],
   "source": [
    "# Function Calling\n",
    "\n",
    "# see https://litellm.vercel.app/docs/completion/function_call\n",
    "\n",
    "# via Huggingface?\n",
    "# https://litellm.vercel.app/docs/providers/huggingface\n",
    "# https://huggingface.co/Trelis/Mixtral-8x7B-Instruct-v0.1-function-calling-v3\n",
    "# https://huggingface.co/Trelis/Mistral-7B-Instruct-v0.1-function-calling-v2\n",
    "\n",
    "# via Anyscale?\n",
    "# https://docs.litellm.ai/docs/providers/anyscale\n",
    "# https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features\n",
    "\n",
    "import os, litellm\n",
    "from litellm import completion\n",
    "\n",
    "# IMPORTANT - Set this to TRUE to add the function to the prompt for Non OpenAI LLMs\n",
    "litellm.add_function_to_prompt = True\n",
    "\n",
    "# The real function is not needed for the LLM. It may be called after the LLM call (not in this code!)\n",
    "def get_current_weather(location):\n",
    "  if location == \"Boston, MA\":\n",
    "    return \"The weather is 12F\"\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "#llm_model = \"gpt-3.5-turbo-1106\"\n",
    "#llm_model = \"gpt-4\"\n",
    "#llm_model = \"claude-2\" # ??? claude answers in response.choices[0]['message']['content']\n",
    "#llm_model = \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "\n",
    "response = completion(model=llm_model, messages=messages, functions=functions)\n",
    "\n",
    "function_found = hasattr(response.choices[0]['message'], 'function_call')\n",
    "if function_found == True:\n",
    "  function_call = response.choices[0]['message']['function_call']\n",
    "  function_call_name = function_call.name\n",
    "  function_call_arguments = function_call.arguments\n",
    "  print(function_call_arguments)\n",
    "else:\n",
    "  if llm_model == \"claude-2\":\n",
    "    print(response.choices[0]['message']['content'])\n",
    "  else:\n",
    "    print('No function found')\n",
    "\n",
    "print('\\n')\n",
    "print(response.choices[0]['message']['content'])\n",
    "print('\\n')\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP0kOug2Vxh3"
   },
   "outputs": [],
   "source": [
    "import os, litellm\n",
    "from litellm import completion\n",
    "\n",
    "litellm.add_function_to_prompt = False\n",
    "\n",
    "functions_string = \"\"\"[\n",
    "  {\n",
    "    \"name\": \"get_risk_data\",\n",
    "    \"description\": \"Daten zum Versicherungsnehmer und seiner Risiken\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"Versicherungssumme\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"Versicherungssumme oder Deckungssumme der Versicherung, z. B. 100000\"\n",
    "        },\n",
    "        \"Versicherungsnehmer_Name\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Name des versicherten Unternehmens, z. B. 'Testfirma GmbH'\"\n",
    "        },\n",
    "        \"Versicherungsnehmer_Anschrift\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Anschrift des versicherten Unternehmens: Strasse, PLZ, Ort, z. B. 'Musterstr. 10, 10000 Berlin'\"\n",
    "        },\n",
    "        \"Versicherungsnehmer_Branche\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Branche bzw. Tätigkeitsbereich des versicherten Unternehmens, z. B. 'Textilproduktion'\"\n",
    "        },\n",
    "        \"Versicherungsnehmer_Umsatz\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Jahresumsatz des versicherten Unternehmens, z. B. 23000000\"\n",
    "        },\n",
    "        \"Vorschäden_benannt\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Informationen zu früheren Schadensfällen, z. B. 'Ja, in 2019 gab es einen Schaden mit folgenden Details'\"\n",
    "        },\n",
    "      },\n",
    "      \"required\": [\"Versicherungssumme\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "functions=eval(functions_string)\n",
    "\n",
    "email_test_text = \"\"\"wir hoffen, Sie hatten einen angenehmen Feiertag.\n",
    "\n",
    "Zu unserer besteMeiermen Kundenverbindung Zorrsen Beteiligungsgesellschaft mbH bitten wir um Ihre Quotierung zur D&O-Versicherung per 01.01.2024.\n",
    "\n",
    "Die aktuelle Versicherungssumme beträgt 5,5 Mio. € zu einer Jahresprämie in Höhe von 7.920 € netto.\n",
    "Der Umsatz im letzten Jahr betrug 78,5 Millionen EUR.\n",
    "\n",
    "Beigefügt erhalten Sie die bisherigen Vertragsunterlagen sowie ein Organigramm. Versichert werden soll die Zorrsen Beteiligungsgesellschaft mbH als VN und die darunterliegenden Tochtergesellschaften (gelb markiert).\n",
    "\n",
    "Es gibt einen laufenden D&O-Schadensfall aufgrund einer Inanspruchnahme eines ehemaligen Geschäftsführers, welcher im Jahr 2017 entlassen wurde. Ihm wird vorgeworfen, für ein damaliges Bauvorhaben das Budget deutlich überzogen zu haben.\n",
    "\n",
    "Für Ihre Rückmeldung vielen Dank im Voraus.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Extrahiere die Risikodaten: \" + email_test_text}\n",
    "]\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "#llm_model = \"gpt-3.5-turbo-1106\"\n",
    "#llm_model = \"gpt-4\"\n",
    "#llm_model = \"claude-2\" # ??? claude answers in response.choices[0]['message']['content']\n",
    "#llm_model = \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "\n",
    "response = completion(model=llm_model, messages=messages, functions=functions)\n",
    "\n",
    "function_found = hasattr(response.choices[0]['message'], 'function_call')\n",
    "if function_found == True:\n",
    "  function_call = response.choices[0]['message']['function_call']\n",
    "  function_call_name = function_call.name\n",
    "  function_call_arguments = function_call.arguments\n",
    "  print(function_call_arguments)\n",
    "else:\n",
    "  if llm_model == \"claude-2\":\n",
    "    print(response.choices[0]['message']['content'])\n",
    "  else:\n",
    "    print('No function found')\n",
    "\n",
    "print('\\n')\n",
    "print(response.choices[0]['message']['content'])\n",
    "print('\\n')\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NNvVCYTQJuJ"
   },
   "outputs": [],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSWhfyvFXDbr"
   },
   "source": [
    "# Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLzlvIiwODXn"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "content = \"This is a piece of text. With some text and some more text.\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 10,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(content)\n",
    "\n",
    "print('Number of text chunks: ', len(chunks))\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tadgzYaZYgMW"
   },
   "source": [
    "# Token counting\n",
    "\n",
    "- https://platform.openai.com/tokenizer\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVlFUHhXXwQ6"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "content = \"This is a piece of text. With some text and some more text.\"\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "token_count = len(enc.encode(content))\n",
    "\n",
    "print('Number of tokens: ', token_count)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
